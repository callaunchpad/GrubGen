{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GAN-practice.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "rc_qoyJxkAR2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# yo basic litt intro (from 231n) of Generative Adversarial Networks (GANs)\n",
        "\n",
        "Many of the applications of neural networks that we have explored have been **discriminative models** that take an input and are trained to produce a labeled output. This has ranged from straightforward classification of image categories to sentence generation (which was still phrased as a classification problem, our labels were in vocabulary space and weâ€™d learned a recurrence to capture multi-word labels). In this notebook, we will expand our repetoire, and build **generative models** using neural networks. Specifically, we will learn how to build models which generate novel images that resemble a set of training images.\n",
        "\n",
        "### What is a GAN?\n",
        "\n",
        "In 2014, [Goodfellow et al.](https://arxiv.org/abs/1406.2661) presented a method for training generative models called Generative Adversarial Networks (GANs for short). In a GAN, we build two different neural networks. Our first network is a traditional classification network, called the **discriminator**. We will train the discriminator to take images, and classify them as being real (belonging to the training set) or fake (not present in the training set). Our other network, called the **generator**, will take random noise as input and transform it using a neural network to produce images. The goal of the generator is to fool the discriminator into thinking the images it produced are real.\n",
        "\n",
        "We can think of this back and forth process of the generator ($G$) trying to fool the discriminator ($D$), and the discriminator trying to correctly classify real vs. fake as a minimax game:\n",
        "$$\\underset{G}{\\text{minimize}}\\; \\underset{D}{\\text{maximize}}\\; \\mathbb{E}_{x \\sim p_\\text{data}}\\left[\\log D(x)\\right] + \\mathbb{E}_{z \\sim p(z)}\\left[\\log \\left(1-D(G(z))\\right)\\right]$$\n",
        "where $x \\sim p_\\text{data}$ are samples from the input data, $z \\sim p(z)$ are the random noise samples, $G(z)$ are the generated images using the neural network generator $G$, and $D$ is the output of the discriminator, specifying the probability of an input being real. In [Goodfellow et al.](https://arxiv.org/abs/1406.2661), they analyze this minimax game and show how it relates to minimizing the Jensen-Shannon divergence between the training data distribution and the generated samples from $G$.\n",
        "\n",
        "To optimize this minimax game, we will aternate between taking gradient *descent* steps on the objective for $G$, and gradient *ascent* steps on the objective for $D$:\n",
        "1. update the **generator** ($G$) to minimize the probability of the __discriminator making the correct choice__. \n",
        "2. update the **discriminator** ($D$) to maximize the probability of the __discriminator making the correct choice__.\n",
        "\n",
        "While these updates are useful for analysis, they do not perform well in practice. Instead, we will use a different objective when we update the generator: maximize the probability of the **discriminator making the incorrect choice**. This small change helps to allevaiate problems with the generator gradient vanishing when the discriminator is confident. This is the standard update used in most GAN papers, and was used in the original paper from [Goodfellow et al.](https://arxiv.org/abs/1406.2661). \n",
        "\n",
        "In this assignment, we will alternate the following updates:\n",
        "1. Update the generator ($G$) to maximize the probability of the discriminator making the incorrect choice on generated data:\n",
        "$$\\underset{G}{\\text{maximize}}\\;  \\mathbb{E}_{z \\sim p(z)}\\left[\\log D(G(z))\\right]$$\n",
        "2. Update the discriminator ($D$), to maximize the probability of the discriminator making the correct choice on real and generated data:\n",
        "$$\\underset{D}{\\text{maximize}}\\; \\mathbb{E}_{x \\sim p_\\text{data}}\\left[\\log D(x)\\right] + \\mathbb{E}_{z \\sim p(z)}\\left[\\log \\left(1-D(G(z))\\right)\\right]$$\n",
        "\n",
        "### What else is there?\n",
        "Since 2014, GANs have exploded into a huge research area, with massive [workshops](https://sites.google.com/site/nips2016adversarial/), and [hundreds of new papers](https://github.com/hindupuravinash/the-gan-zoo). Compared to other approaches for generative models, they often produce the highest quality samples but are some of the most difficult and finicky models to train (see [this github repo](https://github.com/soumith/ganhacks) that contains a set of 17 hacks that are useful for getting models working). Improving the stabiilty and robustness of GAN training is an open research question, with new papers coming out every day! For a more recent tutorial on GANs, see [here](https://arxiv.org/abs/1701.00160). There is also some even more recent exciting work that changes the objective function to Wasserstein distance and yields much more stable results across model architectures: [WGAN](https://arxiv.org/abs/1701.07875), [WGAN-GP](https://arxiv.org/abs/1704.00028).\n",
        "\n",
        "\n",
        "GANs are not the only way to train a generative model! For other approaches to generative modeling check out the [deep generative model chapter](http://www.deeplearningbook.org/contents/generative_models.html) of the Deep Learning [book](http://www.deeplearningbook.org). Another popular way of training neural networks as generative models is Variational Autoencoders (co-discovered [here](https://arxiv.org/abs/1312.6114) and [here](https://arxiv.org/abs/1401.4082)). Variational autoencoders combine neural networks with variational inference to train deep generative models. These models tend to be far more stable and easier to train but currently don't produce samples that are as pretty as GANs."
      ]
    },
    {
      "metadata": {
        "id": "fYxvAqecrHNK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Practice: building a MNIST-M GAN!\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "0FvfbKWaqyNI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "\n",
        "import pickle as pkl\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1UOVW0Qrq1KB",
        "colab_type": "code",
        "outputId": "69b71432-6fd9-40dc-9621-e956cc1e42e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        }
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-2-8bf8ae5a5303>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TfPobV5XrD58",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now, please run python create_mnistm.py to create \"mnistm_data.pkl\"\n"
      ]
    },
    {
      "metadata": {
        "id": "bcUhOfQ0rU2c",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#some UTILITY FUNCTIONS\n",
        "def preprocess_img(x):\n",
        "    return 2 * x - 1.0\n",
        "  \n",
        "def deprocess_img(x):\n",
        "    return (x + 1.0) / 2.0\n",
        "\n",
        "def show_images(images):\n",
        "    images = np.reshape(images, [images.shape[0], -1])  # images reshape to (batch_size, D)\n",
        "    sqrtn = int(np.ceil(np.sqrt(images.shape[0])))\n",
        "    sqrtimg = int(np.ceil(np.sqrt(images.shape[1])))\n",
        "\n",
        "    fig = plt.figure(figsize=(sqrtn, sqrtn))\n",
        "    gs = gridspec.GridSpec(sqrtn, sqrtn)\n",
        "    gs.update(wspace=0.05, hspace=0.05)\n",
        "\n",
        "    for i, img in enumerate(images):\n",
        "        ax = plt.subplot(gs[i])\n",
        "        plt.axis('off')\n",
        "        ax.set_xticklabels([])\n",
        "        ax.set_yticklabels([])\n",
        "        ax.set_aspect('equal')\n",
        "        plt.imshow(img.reshape([sqrtimg,sqrtimg]))\n",
        "    return\n",
        "\n",
        "def shuffle_aligned_list(data):\n",
        "    \"\"\"Shuffle arrays in a list by shuffling each array identically.\"\"\"\n",
        "    num = data[0].shape[0]\n",
        "    p = np.random.permutation(num)\n",
        "    return [d[p] for d in data]\n",
        "\n",
        "def batch_generator(data, batch_size, shuffle=True):\n",
        "    \"\"\"Generate batches of data.\n",
        "    \n",
        "    Given a list of array-like objects, generate batches of a given\n",
        "    size by yielding a list of array-like objects corresponding to the\n",
        "    same slice of each input.\n",
        "    \"\"\"\n",
        "    if shuffle:\n",
        "        data = shuffle_aligned_list(data)\n",
        "\n",
        "    batch_count = 0\n",
        "    while True:\n",
        "        if batch_count * batch_size + batch_size >= len(data[0]):\n",
        "            batch_count = 0\n",
        "\n",
        "            if shuffle:\n",
        "                data = shuffle_aligned_list(data)\n",
        "\n",
        "        start = batch_count * batch_size\n",
        "        end = start + batch_size\n",
        "        batch_count += 1\n",
        "        yield [d[start:end] for d in data]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1l4E2XIEpJgC",
        "colab_type": "code",
        "outputId": "ae124a0f-0ed8-4549-e154-3b30b79b0450",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        }
      },
      "cell_type": "code",
      "source": [
        "show_images(mnist.test.images[3:19])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOwAAADnCAYAAAAdFLrXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nPMIuWMPwCLtgDcMj/h+57ApdQUxNkwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 288x288 with 16 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "BeQ029AYyEB4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Code writing begins below"
      ]
    },
    {
      "metadata": {
        "id": "HXNJCPcmkWVZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Write a method to generate a uniform noise vector:\n",
        "# use tf.random_uniform\n",
        "\n",
        "def sample_noise(batch_size, dim):\n",
        "    \"\"\"Generate random uniform noise from -1 to 1.\n",
        "    \n",
        "    Inputs:\n",
        "    - batch_size: integer giving the batch size of noise to generate\n",
        "    - dim: integer giving the dimension of the the noise to generate\n",
        "    \n",
        "    Returns:\n",
        "    TensorFlow Tensor containing uniform noise in [-1, 1] with shape [batch_size, dim]\n",
        "    \"\"\"\n",
        "    return SOMETHING_SOMETHING"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MK0dNQaelC48",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Discriminator\n",
        "Our first step is to build a discriminator. You should use the layers in `tf.layers` to build the model.\n",
        "All fully connected layers should include bias terms. For initialization, just use the default initializer used by the `tf.layers` functions.\n",
        "\n",
        "*Be sure to check the dimensions of x and reshape when needed*, fully connected blocks expect [N,D] Tensors while conv2d blocks expect [N,H,W,C] Tensors. Please use `tf.layers` to define the following architecture:\n",
        "\n",
        "Recommended \n",
        "Architecture:\n",
        "* Conv2D: 32 Filters, 5x5, Stride 1, padding 0\n",
        "* Leaky ReLU (tf.nn.leaky_relu)\n",
        "* Max Pool (tf.layers.max_pooling2d) 2x2, Stride 2\n",
        "* Conv2D: 64 Filters, 5x5, Stride 1, padding 0\n",
        "* Leaky ReLU\n",
        "* Max Pool 2x2, Stride 2\n",
        "* Flatten (tf.layers.flatten)\n",
        "* Fully Connected with output size 4 x 4 x 64\n",
        "* Leaky ReLU(alpha=0.01)\n",
        "* Fully Connected with output size 1\n",
        "\n",
        "Once again, please use biases for all convolutional and fully connected layers, and use the default parameter initializers. Note that a padding of 0 can be accomplished with the 'VALID' padding option."
      ]
    },
    {
      "metadata": {
        "id": "iutoO3oSkiGb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Write a discriminator model\n",
        "\n",
        "def discriminator(x):\n",
        "    \"\"\"Compute discriminator score for a batch of input images.\n",
        "    \n",
        "    Inputs:\n",
        "    - x: TensorFlow Tensor of flattened input images, shape [batch_size, 784]\n",
        "    \n",
        "    Returns:\n",
        "    TensorFlow Tensor with shape [batch_size, 1], containing the score \n",
        "    for an image being real for each input image.\n",
        "    \"\"\"\n",
        "    with tf.variable_scope(\"discriminator\"):\n",
        "        #write your discriminator model here\n",
        "        SOMETHING_SOMETHING\n",
        "        logits = x\n",
        "        return logits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gjy2dOxHlFUh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Generator\n",
        "Now to build a generator. Please use `tf.layers` for your implementation. You might find the documentation for [tf.layers.conv2d_transpose](https://www.tensorflow.org/api_docs/python/tf/layers/conv2d_transpose) useful. The architecture is as follows.\n",
        "\n",
        "Recommended Architecture:\n",
        "* Fully connected with output size 1024 \n",
        "* `ReLU` (tf.nn.relu)\n",
        "* BatchNorm (tf.layers.batch_normalization)\n",
        "* Fully connected with output size 7 x 7 x 128 \n",
        "* `ReLU`\n",
        "* BatchNorm\n",
        "* Resize into Image Tensor of size 7, 7, 128\n",
        "* Conv2D^T (transpose) (tf.layers.conv2d_transpose): 64 filters of 4x4, stride 2\n",
        "* `ReLU`\n",
        "* BatchNorm\n",
        "* Conv2d^T (transpose): 1 filter of 4x4, stride 2\n",
        "* `TanH`\n",
        "\n",
        "Once again, use biases for the fully connected and transpose convolutional layers. Please use the default initializers for your parameters. For padding, choose the 'same' option for transpose convolutions. For Batch Normalization, assume we are always in 'training' mode."
      ]
    },
    {
      "metadata": {
        "id": "plSE06QNlMCL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def generator(z):\n",
        "    \"\"\"Generate images from a random noise vector.\n",
        "    \n",
        "    Inputs:\n",
        "    - z: TensorFlow Tensor of random noise with shape [batch_size, noise_dim]\n",
        "    \n",
        "    Returns:\n",
        "    TensorFlow Tensor of generated images, with shape [batch_size, 784].\n",
        "    \"\"\"\n",
        "    with tf.variable_scope(\"generator\"):\n",
        "        #write your generator model here\n",
        "        SOMETHING_SOMETHING\n",
        "        img = z\n",
        "        \n",
        "        return img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_hLIf9fCmsWM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# GAN Loss\n",
        "\n",
        "Compute the generator and discriminator loss. The generator loss is:\n",
        "$$\\ell_G  =  \\mathbb{E}_{z \\sim p(z)}\\left[\\log D(G(z))\\right]$$\n",
        "and the discriminator loss is:\n",
        "$$ \\ell_D = \\mathbb{E}_{x \\sim p_\\text{data}}\\left[\\log D(x)\\right] + \\mathbb{E}_{z \\sim p(z)}\\left[\\log \\left(1-D(G(z))\\right)\\right]$$\n",
        "\n",
        "\n",
        "**HINTS**: Use [tf.ones_like](https://www.tensorflow.org/api_docs/python/tf/ones_like) and [tf.zeros_like](https://www.tensorflow.org/api_docs/python/tf/zeros_like) to generate labels for your discriminator. Use [tf.nn.sigmoid_cross_entropy_with_logits](https://www.tensorflow.org/api_docs/python/tf/nn/sigmoid_cross_entropy_with_logits) to help compute your loss function. Instead of computing the expectation, we will be averaging over elements of the minibatch, so make sure to combine the loss by averaging instead of summing."
      ]
    },
    {
      "metadata": {
        "id": "QnYF2AwKnInb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def gan_loss(logits_real, logits_fake):\n",
        "    \"\"\"Compute the GAN loss.\n",
        "    \n",
        "    Inputs:\n",
        "    - logits_real: Tensor, shape [batch_size, 1], output of discriminator\n",
        "        Unnormalized score that the image is real for each real image\n",
        "    - logits_fake: Tensor, shape[batch_size, 1], output of discriminator\n",
        "        Unnormalized score that the image is real for each fake image\n",
        "    \n",
        "    Returns:\n",
        "    - D_loss: discriminator loss scalar\n",
        "    - G_loss: generator loss scalar\n",
        "    \n",
        "    HINT: for the discriminator loss, you'll want to do the averaging separately for\n",
        "    its two components, and then add them together (instead of averaging once at the very end).\n",
        "    \"\"\"\n",
        "       \n",
        "    G_loss = SOMETHING_SOMETHING\n",
        "    D_loss = SOMETHING_SOMETHING\n",
        "    \n",
        "    return D_loss, G_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "X7ilNyM6AOTv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## The code block below is written out for you\n",
        "Take the time to read through the code to understand it"
      ]
    },
    {
      "metadata": {
        "id": "NZNpvbKbnjvr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tf.reset_default_graph()\n",
        "\n",
        "# number of images for each batch\n",
        "batch_size = 128\n",
        "# our noise dimension\n",
        "noise_dim = 96\n",
        "\n",
        "# placeholder for images from the training dataset\n",
        "x = tf.placeholder(tf.float32, [None, 784])\n",
        "# random noise fed into our generator\n",
        "z = sample_noise(batch_size, noise_dim)\n",
        "# generated images\n",
        "G_sample = generator(z)\n",
        "\n",
        "with tf.variable_scope(\"\") as scope:\n",
        "    logits_real = discriminator(preprocess_img(x))\n",
        "    # Re-use discriminator weights on new inputs\n",
        "    scope.reuse_variables()\n",
        "    logits_fake = discriminator(G_sample)\n",
        "\n",
        "# Get the list of variables for the discriminator and generator\n",
        "D_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, 'discriminator')\n",
        "G_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, 'generator') \n",
        "\n",
        "# get our solver\n",
        "D_solver = tf.train.AdamOptimizer(learning_rate=1e-3, beta1=.5)\n",
        "G_solver = tf.train.AdamOptimizer(learning_rate=1e-3, beta1=.5)\n",
        "\n",
        "# get our loss\n",
        "D_loss, G_loss = gan_loss(logits_real, logits_fake)\n",
        "\n",
        "# setup training steps\n",
        "D_train_step = D_solver.minimize(D_loss, var_list=D_vars)\n",
        "G_train_step = G_solver.minimize(G_loss, var_list=G_vars)\n",
        "D_extra_step = tf.get_collection(tf.GraphKeys.UPDATE_OPS, 'discriminator')\n",
        "G_extra_step = tf.get_collection(tf.GraphKeys.UPDATE_OPS, 'generator')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "c5PuajyOp98n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sess = tf.Session() \n",
        "init = tf.global_variables_initializer() \n",
        "sess.run(init)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rxgNPETgsmAO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Now write your training loop\n",
        "\n",
        "batch_size = #your batch size\n",
        "Gloss_plot = []\n",
        "Dloss_plot = []\n",
        "num_epochs = 10000\n",
        "k = 1\n",
        "\n",
        "mnist_batch = batch_generator([mnist.train.images, mnist.train.labels], batch_size)\n",
        "for epoch in range(num_epochs + 1):\n",
        "  batch_xs, _ = next(mnist_batch)\n",
        "  \n",
        "  #what do we need to write here\n",
        "  SOMETHING_SOMETHING\n",
        "  \n",
        "  \n",
        "  if epoch % 100 == 0:\n",
        "      print(epoch, \"Batch Loss:\", D_loss_curr, G_loss_curr)\n",
        "  if epoch % 500 == 0:\n",
        "      samples = sess.run(G_sample) \n",
        "      fig = show_images(samples[:16])\n",
        "      plt.show()\n",
        "      print()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "W9ApafqK-k_J",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#see some pics\n",
        "samples = sess.run(G_sample) \n",
        "fig = show_images(samples)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tt_XscIdu-4P",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Visualize loss plot\n",
        "plt.plot(Gloss_plot)\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training loss history')\n",
        "plt.gcf().set_size_inches(30, 10)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1W_W2X_XsD1T",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Visualize loss plot\n",
        "plt.plot(Dloss_plot)\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training loss history')\n",
        "plt.gcf().set_size_inches(30, 10)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "il4JDskwsEb-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}